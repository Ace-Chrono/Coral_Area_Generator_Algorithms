{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries and Dependancies"
      ],
      "metadata": {
        "id": "CUQ1pGLPfIcC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZnsJf5EDTMS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d309e9bd-afdc-45d3-9b75-285139d0a355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sam2'...\n",
            "remote: Enumerating objects: 1070, done.\u001b[K\n",
            "remote: Total 1070 (delta 0), reused 0 (delta 0), pack-reused 1070 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1070/1070), 134.70 MiB | 14.36 MiB/s, done.\n",
            "Resolving deltas: 100% (375/375), done.\n",
            "/content/sam2\n",
            "Obtaining file:///content/sam2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.20.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (1.26.4)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n",
            "Collecting hydra-core>=1.3.2 (from SAM-2==1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting iopath>=0.1.10 (from SAM-2==1.0)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.1.0)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->SAM-2==1.0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->SAM-2==1.0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (24.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.12.2)\n",
            "Collecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->SAM-2==1.0) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m19.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: SAM-2, antlr4-python3-runtime, iopath\n",
            "  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SAM-2: filename=sam_2-1.0-0.editable-cp311-cp311-linux_x86_64.whl size=13799 sha256=ede154bac65aba427238dd480a1ad8ff7e8cd4efc7424edcef4efe4b077d6d1b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-89qdz62r/wheels/76/dc/37/006d341f6080de50c00d031747ee8a1a03f3fb513175bce1c0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=92e48b8508542a53c8440b75bfeed46b5ff613473d8c55e5cfb006250a1f45a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=931ace76b0d09939f55a408facb968ec37b332dc6c166cc4bdda549eb61ba0e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built SAM-2 antlr4-python3-runtime iopath\n",
            "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, hydra-core, nvidia-cusolver-cu12, SAM-2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed SAM-2-1.0 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 iopath-0.1.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 portalocker-3.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "29c5c4f8a74d4acb999cf7b7e48cac70"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/sam2.git\n",
        "%cd sam2\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "tfbwwk-8ZVqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9c4538-8723-4c07-b848-20cc0984a86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.73-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.73-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.6/914.6 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.73 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "from google.colab import drive, files\n",
        "from pycocotools import mask as coco_mask\n",
        "\n",
        "from torch.onnx.symbolic_opset11 import hstack\n",
        "\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "Cysjm28ELV4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3022b0-ede2-4af3-bbcd-501d20d0d7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = YOLO(\"/content/gdrive/MyDrive/Coral SAM 2 Tuner Folder/2733_augmented_adjusted_YOLOV11.pt\")"
      ],
      "metadata": {
        "id": "soktN5v8a2PC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc76d4cc-79f2-4042-e449-ca3697e5e7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Manipulation & Extraction Methods"
      ],
      "metadata": {
        "id": "aWuhkA5bfOwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/gdrive/MyDrive/Coral SAM 2 Tuner Folder/coral_masks.v17-v2-mature.sam2/\"\n",
        "train_dir = os.path.join(data_dir, \"train/\")\n",
        "test_dir = os.path.join(data_dir, \"test/\")\n",
        "valid_dir = os.path.join(data_dir, \"valid/\")\n",
        "\n",
        "def extract_dataset(directory):\n",
        "    image_arrays = {}\n",
        "    binary_masks = {}\n",
        "    bbox_coords = {}\n",
        "    skipped_count = 0\n",
        "    image_id = 0\n",
        "\n",
        "    for file_name in os.listdir(directory):\n",
        "        if file_name.endswith('.json'):\n",
        "            json_file_path = os.path.join(directory, file_name)\n",
        "            with open(json_file_path, 'r') as f:\n",
        "                coco_data = json.load(f)\n",
        "\n",
        "            annotations = coco_data['annotations']\n",
        "            if not annotations:  # Fix: Skip if annotations are empty\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            image_info = coco_data['image']\n",
        "            if not image_info:  # Fix: Skip if image metadata is missing\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            file_name = image_info['file_name']\n",
        "            if not file_name:\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            image_path = os.path.join(directory, file_name)\n",
        "            if not os.path.exists(image_path):  # Check if image file exists\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            image = cv2.imread(image_path)\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            annotation = annotations[0]\n",
        "            segmentation = annotation['segmentation']\n",
        "            if not segmentation:  # Skip if segmentation is missing\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            \"\"\"\n",
        "            results = model.predict(image, verbose=False)\n",
        "            for result in results:\n",
        "                boxes = result.boxes\n",
        "            if boxes.xyxy.tolist():\n",
        "                bbox = boxes.xyxy.tolist()[0]\n",
        "            else:\n",
        "                bbox = [0, 1024, 0, 1024]\n",
        "\n",
        "            if bbox == [0, 1024, 0, 1024]:\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            bbox_array = np.array(bbox)\n",
        "            \"\"\"\n",
        "\n",
        "            bbox = annotation['bbox']\n",
        "            if not bbox:  # Skip if bbox is missing\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "            x_min, y_min, width, height = bbox\n",
        "            x_max = x_min + width\n",
        "            y_max = y_min + height\n",
        "            bbox_array = np.array([x_min, y_min, x_max, y_max])\n",
        "\n",
        "            binary_mask = coco_mask.decode(segmentation)\n",
        "            if binary_mask is None:  # Ensure mask is valid\n",
        "                skipped_count += 1\n",
        "                continue\n",
        "\n",
        "            bbox_coords[image_id] = (bbox_array)\n",
        "            binary_masks[image_id] = binary_mask\n",
        "            image_arrays[image_id] = image\n",
        "\n",
        "            image_id += 1\n",
        "\n",
        "    print(f\"Skipped {skipped_count} images in the {directory} dataset.\")\n",
        "    return image_arrays, binary_masks, bbox_coords\n",
        "\n",
        "dataset_indices = {}\n",
        "dataset_index_ptr = {}\n",
        "\n",
        "def read_single(dataset_type, reset_epoch=False):\n",
        "    global dataset_indices, dataset_index_ptr\n",
        "\n",
        "    if (dataset_type == \"train\"):\n",
        "        image_arrays = train_image_arrays\n",
        "        binary_masks = train_binary_masks\n",
        "        bbox_coords = train_bbox_coords\n",
        "    elif (dataset_type == \"test\"):\n",
        "        image_arrays = test_image_arrays\n",
        "        binary_masks = test_binary_masks\n",
        "        bbox_coords = test_bbox_coords\n",
        "    elif (dataset_type == \"val\"):\n",
        "        image_arrays = valid_image_arrays\n",
        "        binary_masks = valid_binary_masks\n",
        "        bbox_coords = valid_bbox_coords\n",
        "\n",
        "    # Initialize indices if not already done\n",
        "    if dataset_type not in dataset_indices:\n",
        "        dataset_indices[dataset_type] = np.arange(len(image_arrays))\n",
        "        np.random.shuffle(dataset_indices[dataset_type])  # Shuffle indices\n",
        "        dataset_index_ptr[dataset_type] = 0  # Start at the beginning\n",
        "\n",
        "    # Reset and reshuffle if epoch is flagged to reset\n",
        "    if reset_epoch or dataset_index_ptr[dataset_type] >= len(dataset_indices[dataset_type]):\n",
        "        dataset_indices[dataset_type] = np.arange(len(image_arrays))\n",
        "        np.random.shuffle(dataset_indices[dataset_type])\n",
        "        dataset_index_ptr[dataset_type] = 0\n",
        "\n",
        "    # Fetch the next index and increment pointer\n",
        "    entry = dataset_indices[dataset_type][dataset_index_ptr[dataset_type]]\n",
        "    dataset_index_ptr[dataset_type] += 1  # Increment pointer\n",
        "\n",
        "    Img = image_arrays[entry]\n",
        "    mask = binary_masks[entry]\n",
        "    bbox = bbox_coords[entry]\n",
        "\n",
        "    return Img, mask, bbox\n",
        "\n",
        "def read_batch(dataset_type, current_iteration, interval, batch_size=4):\n",
        "    limage = []\n",
        "    lmask = []\n",
        "    lbbox = []\n",
        "    for i in range(batch_size):\n",
        "            image,mask,bbox = read_single(dataset_type, reset_epoch=(current_iteration % interval == 0))\n",
        "            limage.append(image)\n",
        "            lmask.append(mask)\n",
        "            lbbox.append(bbox)\n",
        "\n",
        "    return limage, np.array(lmask), np.array(lbbox)\n",
        "\n",
        "def return_dataset_size(dataset_type):\n",
        "    if (dataset_type == \"train\"):\n",
        "        return len(train_image_arrays)\n",
        "    elif (dataset_type == \"test\"):\n",
        "        return len(test_image_arrays)\n",
        "    elif (dataset_type == \"val\"):\n",
        "        return len(valid_image_arrays)\n",
        "\n",
        "\n",
        "def get_itr_interval(dataset_type, epochs):\n",
        "  if (dataset_type == \"train\"):\n",
        "      return (len(train_image_arrays) // 4) * epochs, (len(train_image_arrays) // 4)\n",
        "  elif (dataset_type == \"test\"):\n",
        "      return (len(test_image_arrays) // 4) * epochs, (len(test_image_arrays) // 4)\n",
        "  elif (dataset_type == \"val\"):\n",
        "      return (len(valid_image_arrays) // 4) * epochs, (len(valid_image_arrays) // 4)\n",
        "\n",
        "train_image_arrays, train_binary_masks, train_bbox_coords = extract_dataset(train_dir)\n",
        "test_image_arrays, test_binary_masks, test_bbox_coords = extract_dataset(test_dir)\n",
        "valid_image_arrays, valid_binary_masks, valid_bbox_coords = extract_dataset(valid_dir)"
      ],
      "metadata": {
        "id": "W2ztzhsNLZVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb770ecb-fb0c-4b94-f28c-96d052b66a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped 0 images in the /content/gdrive/MyDrive/Coral SAM 2 Tuner Folder/coral_masks.v17-v2-mature.sam2/train/ dataset.\n",
            "Skipped 0 images in the /content/gdrive/MyDrive/Coral SAM 2 Tuner Folder/coral_masks.v17-v2-mature.sam2/test/ dataset.\n",
            "Skipped 0 images in the /content/gdrive/MyDrive/Coral SAM 2 Tuner Folder/coral_masks.v17-v2-mature.sam2/valid/ dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SAM 2 Training"
      ],
      "metadata": {
        "id": "RX_eQ8CvfaBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "\n",
        "sam2_checkpoint = \"/content/gdrive/MyDrive/Coral SAM 2 Tuner Folder/sam2.1_hiera_large.pt\" # path to model weight\n",
        "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\" #  model config\n",
        "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\") # load model\n",
        "predictor = SAM2ImagePredictor(sam2_model)\n",
        "\n",
        "# Set training parameters\n",
        "\n",
        "predictor.model.sam_mask_decoder.train(True) # enable training of mask decoder\n",
        "predictor.model.sam_prompt_encoder.train(True) # enable training of prompt encoder\n",
        "predictor.model.image_encoder.train(True) # enable training of image encoder: For this to work you need to scan the code for \"no_grad\" and remove them all\n",
        "optimizer=torch.optim.AdamW(params=predictor.model.parameters(),lr=1e-5,weight_decay=4e-5)\n",
        "scaler = torch.cuda.amp.GradScaler() # mixed precision\n",
        "\n",
        "iterations, VALIDATION_INTERVAL = get_itr_interval(\"train\", 40)\n",
        "\n",
        "def compute_metrics(predictor, dataset_type, batch_size):\n",
        "    \"\"\"Computes validation/test metrics for the given dataset type.\"\"\"\n",
        "    predictor.model.eval()\n",
        "    total_iou, total_loss = 0, 0\n",
        "    num_samples = 0\n",
        "    itr, end = get_itr_interval(dataset_type, 1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(return_dataset_size(dataset_type) // batch_size):\n",
        "            image, mask, input_bbox = read_batch(dataset_type, current_iteration=itr + 1, interval=end, batch_size = 4)\n",
        "            if mask.shape[0] == 0:\n",
        "                continue\n",
        "\n",
        "            predictor.set_image_batch(image)\n",
        "            mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n",
        "                point_coords=None,\n",
        "                point_labels=None,\n",
        "                box=input_bbox,\n",
        "                mask_logits=None,\n",
        "                normalize_coords=True\n",
        "            )\n",
        "            sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
        "                points=None, boxes=unnorm_box, masks=None\n",
        "            )\n",
        "            high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
        "            low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
        "                image_embeddings=predictor._features[\"image_embed\"],\n",
        "                image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
        "                sparse_prompt_embeddings=sparse_embeddings,\n",
        "                dense_prompt_embeddings=dense_embeddings,\n",
        "                multimask_output=True,\n",
        "                repeat_image=False,\n",
        "                high_res_features=high_res_features,\n",
        "            )\n",
        "            prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])\n",
        "            gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
        "            prd_mask = torch.sigmoid(prd_masks[:, 0])\n",
        "            seg_loss = (\n",
        "                -gt_mask * torch.log(prd_mask + 1e-5) - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-5)\n",
        "            ).mean()\n",
        "            inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n",
        "            iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n",
        "\n",
        "            total_loss += seg_loss.item()\n",
        "            total_iou += iou.mean().item()\n",
        "            num_samples += 1\n",
        "\n",
        "    return total_loss / num_samples, total_iou / num_samples\n",
        "\n",
        "# Training loop\n",
        "\n",
        "best_val_iou = -float('inf')  # Initialize to negative infinity to always save the best model\n",
        "best_model_path = \"/content/gdrive/MyDrive/Coral SAM 2 Tuner Folder/best_SAM2.pth\"\n",
        "\n",
        "patience = 5  # Number of validation intervals to wait before stopping\n",
        "no_improve_counter = 0  # Counter to track the number of validation intervals without improvement\n",
        "best_val_loss = float('inf')  # Initialize best validation loss\n",
        "min_lr = 1e-7  # Minimum learning rate for stopping\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=2, verbose=True, min_lr=min_lr\n",
        ")\n",
        "\n",
        "for itr in range(iterations):\n",
        "    with torch.cuda.amp.autocast():  # cast to mixed precision\n",
        "        # Load data batch\n",
        "        image, mask, input_bbox = read_batch(\"train\", current_iteration=itr + 1, interval=VALIDATION_INTERVAL, batch_size = 4)  # Update the function to provide bounding boxes\n",
        "        if mask.shape[0] == 0:\n",
        "            continue  # Ignore empty batches\n",
        "\n",
        "        predictor.set_image_batch(image)  # Apply SAM image encoder to the image\n",
        "\n",
        "        # Prompt encoding using bounding boxes\n",
        "        mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(\n",
        "            point_coords=None,\n",
        "            point_labels=None,\n",
        "            box=input_bbox,  # Use bounding boxes here\n",
        "            mask_logits=None,\n",
        "            normalize_coords=True\n",
        "        )\n",
        "        sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(\n",
        "            points=None,\n",
        "            boxes=unnorm_box,  # Pass the bounding boxes to the encoder\n",
        "            masks=None\n",
        "        )\n",
        "\n",
        "        # Mask decoder\n",
        "        high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
        "        low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(\n",
        "            image_embeddings=predictor._features[\"image_embed\"],\n",
        "            image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),\n",
        "            sparse_prompt_embeddings=sparse_embeddings,\n",
        "            dense_prompt_embeddings=dense_embeddings,\n",
        "            multimask_output=True,\n",
        "            repeat_image=False,\n",
        "            high_res_features=high_res_features,\n",
        "        )\n",
        "        prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])  # Upscale the masks to the original image resolution\n",
        "\n",
        "        # Segmentation loss calculation\n",
        "        gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
        "        prd_mask = torch.sigmoid(prd_masks[:, 0])  # Turn logit map to probability map\n",
        "        seg_loss = (\n",
        "            -gt_mask * torch.log(prd_mask + 1e-5) - (1 - gt_mask) * torch.log((1 - prd_mask) + 1e-5)\n",
        "        ).mean()  # Cross entropy loss\n",
        "\n",
        "        # Score loss calculation (Intersection over Union - IOU)\n",
        "        inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n",
        "        iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n",
        "        score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n",
        "        loss = seg_loss + score_loss * 0.05  # Mix losses\n",
        "\n",
        "        # Apply backpropagation\n",
        "        predictor.model.zero_grad()  # Empty gradient\n",
        "        scaler.scale(loss).backward()  # Backpropagate\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()  # Mixed precision\n",
        "\n",
        "    # Validation step with regularization\n",
        "    if itr % VALIDATION_INTERVAL == 0:\n",
        "        val_loss, val_iou = compute_metrics(predictor, dataset_type=\"val\", batch_size=4)\n",
        "        print(f\"Validation - Step: {itr}, Loss: {val_loss:.4f}, IOU: {val_iou:.4f}\")\n",
        "\n",
        "        # Learning rate adjustment\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            no_improve_counter = 0\n",
        "            # Save best model\n",
        "            torch.save(predictor.model.state_dict(), best_model_path)\n",
        "            print(f\"New best model saved at iteration {itr} with validation loss: {val_loss:.4f}\")\n",
        "        else:\n",
        "            no_improve_counter += 1\n",
        "            print(f\"No improvement in validation loss for {no_improve_counter} intervals.\")\n",
        "\n",
        "        if no_improve_counter >= patience:\n",
        "            print(f\"Early stopping triggered at iteration {itr}. Best validation loss: {best_val_loss:.4f}\")\n",
        "            break\n",
        "\n",
        "# Final evaluation on test set\n",
        "test_loss, test_iou = compute_metrics(predictor, dataset_type=\"test\", batch_size=4)\n",
        "print(f\"Test Results - Loss: {test_loss:.4f}, IOU: {test_iou:.4f}\")"
      ],
      "metadata": {
        "id": "rYjGjjOjDYex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559b0528-7917-4451-d2b8-8f08b4c6a83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-1ec32a234d53>:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler() # mixed precision\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "<ipython-input-5-1ec32a234d53>:82: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # cast to mixed precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Step: 0, Loss: 0.1812, IOU: 0.5707\n",
            "New best model saved at iteration 0 with validation loss: 0.1812\n",
            "Validation - Step: 790, Loss: 0.0131, IOU: 0.9710\n",
            "New best model saved at iteration 790 with validation loss: 0.0131\n",
            "Validation - Step: 1580, Loss: 0.0123, IOU: 0.9726\n",
            "New best model saved at iteration 1580 with validation loss: 0.0123\n",
            "Validation - Step: 2370, Loss: 0.0116, IOU: 0.9739\n",
            "New best model saved at iteration 2370 with validation loss: 0.0116\n",
            "Validation - Step: 3160, Loss: 0.0114, IOU: 0.9741\n",
            "New best model saved at iteration 3160 with validation loss: 0.0114\n",
            "Validation - Step: 3950, Loss: 0.0114, IOU: 0.9743\n",
            "No improvement in validation loss for 1 intervals.\n",
            "Validation - Step: 4740, Loss: 0.0113, IOU: 0.9744\n",
            "New best model saved at iteration 4740 with validation loss: 0.0113\n",
            "Validation - Step: 5530, Loss: 0.0111, IOU: 0.9751\n",
            "New best model saved at iteration 5530 with validation loss: 0.0111\n",
            "Validation - Step: 6320, Loss: 0.0110, IOU: 0.9753\n",
            "New best model saved at iteration 6320 with validation loss: 0.0110\n",
            "Validation - Step: 7110, Loss: 0.0110, IOU: 0.9754\n",
            "New best model saved at iteration 7110 with validation loss: 0.0110\n",
            "Validation - Step: 7900, Loss: 0.0111, IOU: 0.9746\n",
            "No improvement in validation loss for 1 intervals.\n",
            "Validation - Step: 8690, Loss: 0.0110, IOU: 0.9754\n",
            "No improvement in validation loss for 2 intervals.\n",
            "Validation - Step: 9480, Loss: 0.0108, IOU: 0.9756\n",
            "New best model saved at iteration 9480 with validation loss: 0.0108\n",
            "Validation - Step: 10270, Loss: 0.0111, IOU: 0.9758\n",
            "No improvement in validation loss for 1 intervals.\n",
            "Validation - Step: 11060, Loss: 0.0109, IOU: 0.9758\n",
            "No improvement in validation loss for 2 intervals.\n",
            "Validation - Step: 11850, Loss: 0.0109, IOU: 0.9757\n",
            "No improvement in validation loss for 3 intervals.\n",
            "Validation - Step: 12640, Loss: 0.0108, IOU: 0.9762\n",
            "New best model saved at iteration 12640 with validation loss: 0.0108\n",
            "Validation - Step: 13430, Loss: 0.0108, IOU: 0.9760\n",
            "No improvement in validation loss for 1 intervals.\n",
            "Validation - Step: 14220, Loss: 0.0107, IOU: 0.9762\n",
            "New best model saved at iteration 14220 with validation loss: 0.0107\n",
            "Validation - Step: 15010, Loss: 0.0108, IOU: 0.9761\n",
            "No improvement in validation loss for 1 intervals.\n",
            "Validation - Step: 15800, Loss: 0.0107, IOU: 0.9763\n",
            "New best model saved at iteration 15800 with validation loss: 0.0107\n",
            "Validation - Step: 16590, Loss: 0.0108, IOU: 0.9762\n",
            "No improvement in validation loss for 1 intervals.\n",
            "Validation - Step: 17380, Loss: 0.0109, IOU: 0.9760\n",
            "No improvement in validation loss for 2 intervals.\n",
            "Validation - Step: 18170, Loss: 0.0110, IOU: 0.9760\n",
            "No improvement in validation loss for 3 intervals.\n",
            "Validation - Step: 18960, Loss: 0.0108, IOU: 0.9762\n",
            "No improvement in validation loss for 4 intervals.\n",
            "Validation - Step: 19750, Loss: 0.0108, IOU: 0.9762\n",
            "No improvement in validation loss for 5 intervals.\n",
            "Early stopping triggered at iteration 19750. Best validation loss: 0.0107\n",
            "Test Results - Loss: 0.0100, IOU: 0.9760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add training loss and validation loss"
      ],
      "metadata": {
        "id": "0gp64WXsJoYx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}