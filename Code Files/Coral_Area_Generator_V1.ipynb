{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup up CUDA for PyTorch\n",
    "#### *Must download CUDA drive from https://developer.nvidia.com/cuda-downloads and make a venv after in anaconda, not before. Then run the kernel below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHn6z4moM24T",
    "outputId": "b04ddf72-2f9f-44cb-9c45-66c7fbfd30d6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.3.1\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.3.1%2Bcu118-cp312-cp312-win_amd64.whl (2672.9 MB)\n",
      "Collecting torchvision==0.18.1\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.18.1%2Bcu118-cp312-cp312-win_amd64.whl (4.9 MB)\n",
      "Collecting torchaudio==2.3.1\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.3.1%2Bcu118-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "Collecting filelock (from torch==2.3.1)\n",
      "  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from torch==2.3.1) (4.12.2)\n",
      "Collecting sympy (from torch==2.3.1)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "     -------- ------------------------------- 1.3/6.2 MB 6.1 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 3.1/6.2 MB 8.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 5.2/6.2 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.2/6.2 MB 8.4 MB/s eta 0:00:00\n",
      "Collecting networkx (from torch==2.3.1)\n",
      "  Using cached https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from torch==2.3.1) (3.1.4)\n",
      "Collecting fsspec (from torch==2.3.1)\n",
      "  Using cached https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch==2.3.1)\n",
      "  Using cached https://download.pytorch.org/whl/mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Collecting numpy (from torchvision==0.18.1)\n",
      "  Using cached https://download.pytorch.org/whl/numpy-1.26.3-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.18.1)\n",
      "  Using cached https://download.pytorch.org/whl/pillow-10.2.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1)\n",
      "  Using cached https://download.pytorch.org/whl/intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1)\n",
      "  Using cached https://download.pytorch.org/whl/tbb-2021.11.0-py3-none-win_amd64.whl (298 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from jinja2->torch==2.3.1) (2.1.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.3.1)\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, pillow, numpy, networkx, mkl, fsspec, filelock, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.13.1 fsspec-2024.2.0 intel-openmp-2021.4.0 mkl-2021.4.0 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 pillow-10.2.0 sympy-1.13.1 tbb-2021.11.0 torch-2.3.1+cu118 torchaudio-2.3.1+cu118 torchvision-0.18.1+cu118\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "#!pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHn6z4moM24T",
    "outputId": "b04ddf72-2f9f-44cb-9c45-66c7fbfd30d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 11 17:07:22 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   65C    P8             19W /   86W |     611MiB /   8192MiB |      6%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      6724    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      7780    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     12012    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     12048    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15504    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16640    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     18288    C+G   ...a\\Local\\slack\\app-4.39.95\\slack.exe      N/A      |\n",
      "|    0   N/A  N/A     19032    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QqaZoirGcrf"
   },
   "source": [
    "## Setup SAM and YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAxjKnlkO5bh",
    "outputId": "3d2788a7-e1fd-417c-c30d-22660b7a819a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
      "  Cloning https://github.com/facebookresearch/segment-anything.git to c:\\users\\richa_0\\appdata\\local\\temp\\pip-req-build-0kj5ah3a\n",
      "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: segment_anything\n",
      "  Building wheel for segment_anything (setup.py): started\n",
      "  Building wheel for segment_anything (setup.py): finished with status 'done'\n",
      "  Created wheel for segment_anything: filename=segment_anything-1.0-py3-none-any.whl size=36830 sha256=bdb821de8e0fd1f75e47efabf606148bb04d3f3c02e2727837fdc7db997a2d66\n",
      "  Stored in directory: C:\\Users\\richa_0\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-arw72shv\\wheels\\29\\82\\ff\\04e2be9805a1cb48bec0b85b5a6da6b63f647645750a0e42d4\n",
      "Successfully built segment_anything\n",
      "Installing collected packages: segment_anything\n",
      "Successfully installed segment_anything-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git 'C:\\Users\\richa_0\\AppData\\Local\\Temp\\pip-req-build-0kj5ah3a'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/facebookresearch/segment-anything.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjPaUgCCO_UN",
    "outputId": "606039a4-7f7a-4306-ffca-a8ff66eab626"
   },
   "outputs": [],
   "source": [
    "!pip install -q  supervision jupyter_bbox_widget roboflow dataclasses-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Using cached ultralytics-8.3.59-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (1.26.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (1.15.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (2.3.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (0.18.1+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pandas>=1.1.4 (from ultralytics)\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.4->ultralytics)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.12.14)\n",
      "Requirement already satisfied: filelock in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.8.0->ultralytics) (2021.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Using cached ultralytics-8.3.59-py3-none-any.whl (906 kB)\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.5 MB 7.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.1/11.5 MB 8.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.1/11.5 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.5 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 9.0 MB/s eta 0:00:00\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: py-cpuinfo, tzdata, pandas, ultralytics-thop, seaborn, ultralytics\n",
      "Successfully installed pandas-2.2.3 py-cpuinfo-9.0.0 seaborn-0.13.2 tzdata-2024.2 ultralytics-8.3.59 ultralytics-thop-2.0.13\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Downloading imageio-2.36.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from imageio) (1.26.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\richa_0\\anaconda3\\envs\\coral_area_generator\\lib\\site-packages (from imageio) (10.2.0)\n",
      "Downloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.36.1\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ks5PKNw_G8dh"
   },
   "source": [
    "## Setup Computer and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwLbgdDVQhMS",
    "outputId": "003cd6b8-24e8-47e3-981b-5e1c21bf6b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu118\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"vit_h\"\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor # r\"C:\\Users\\richa_0\\Downloads\\sam_model_epoch_24.pth\"\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=r\"C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\V1 Models\\sam_vit_h_4b8939.pth\").to(device=DEVICE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVMUpajOHV9l"
   },
   "source": [
    "#### Add more dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5hFeInNqGCgg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches \n",
    "import torchvision\n",
    "import os\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import supervision as sv\n",
    "from roboflow import Roboflow\n",
    "import imageio.v3 as iio\n",
    "import datetime\n",
    "import json\n",
    "import cv2\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Custom YOLO V8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "model = YOLO(\"yolo8n.pt\")\n",
    "name = \"50_epochs-\"\n",
    "project = \"C:/Users/richa_0/Documents/Coral Research/Machine Learning Models/V1 Models/2612.yolov8/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.train(data=r\"C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\V1 Models\\2612.yolov8\\data.yaml\",\n",
    "                      project=project,\n",
    "                      name=name,\n",
    "                      epochs=50,\n",
    "                      patience=0, #I am setting patience=0 to disable early stopping.\n",
    "                      batch=4,\n",
    "                      imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.2]) #0.6\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375): #Extra method for the SAM inputs that we don't use\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "def show_box(box, ax): #For debugging purposes to check if YOLO V8 is working\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    rect = plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "def show_polygon(polygons, ax):\n",
    "    formatted_polygons = [np.array(polygon).reshape(-1, 2) for polygon in polygons]\n",
    "    for polygon in formatted_polygons:\n",
    "        polygon_patch = patches.Polygon(polygon, closed=True, edgecolor='red', facecolor=(0,0,0,0), lw=2)\n",
    "        ax.add_patch(polygon_patch)\n",
    "\n",
    "def show_ground_truth(area, ax):\n",
    "    ax.text(50, 50, str(area) + \" µm\", color='white', fontsize=16, backgroundcolor='black')\n",
    "\n",
    "def get_area(mask): #Prints the mask onto the image in a blue color\n",
    "    true_count = np.count_nonzero(mask)\n",
    "    return true_count\n",
    "\n",
    "def mask_to_polygon(mask):\n",
    "    # Convert mask to binary if it is not already\n",
    "    if mask.max() > 1:\n",
    "        _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    else:\n",
    "        binary_mask = (mask * 255).astype(np.uint8)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        # Simplify the contour to reduce the number of points\n",
    "        epsilon = 0.001 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "        # Extract points and flatten the list\n",
    "        polygon = approx.reshape(-1, 2).tolist()\n",
    "        flat_polygon = [point for sublist in polygon for point in sublist]\n",
    "        polygons.append(flat_polygon)\n",
    "\n",
    "    return polygons\n",
    "\n",
    "def get_physical_tag(image): #Gets the physical conversion ratios through a library\n",
    "    physical_size_x = 1\n",
    "    physical_size_y = 1\n",
    "    exifdata = image.getexif()\n",
    "    for tagid in exifdata:\n",
    "        tagname = TAGS.get(tagid, tagid)\n",
    "        if tagname == \"ImageDescription\":\n",
    "            try:\n",
    "                value = exifdata.get(tagid)\n",
    "                start_index_x = value.find('PhysicalSizeX=\"') + len('PhysicalSizeX=\"')\n",
    "                end_index_x = value.find('\"', start_index_x)\n",
    "                physical_size_x = value[start_index_x:end_index_x]\n",
    "                start_index_x_unit = value.find('PhysicalSizeXUnit=\"') + len('PhysicalSizeXUnit=\"')\n",
    "                end_index_x_unit = value.find('\"', start_index_x_unit)\n",
    "                physical_size_x_unit = value[start_index_x_unit:end_index_x_unit]\n",
    "                start_index_y = value.find('PhysicalSizeY=\"') + len('PhysicalSizeY=\"')\n",
    "                end_index_y = value.find('\"', start_index_y)\n",
    "                physical_size_y = value[start_index_y:end_index_y]\n",
    "                start_index_y_unit = value.find('PhysicalSizeYUnit=\"') + len('PhysicalSizeYUnit=\"')\n",
    "                end_index_y_unit = value.find('\"', start_index_y_unit)\n",
    "                physical_size_y_unit = value[start_index_y_unit:end_index_y_unit]\n",
    "            except Exception as e:\n",
    "                print(f'Failed to process {image}: {e}')\n",
    "                continue\n",
    "\n",
    "    if (physical_size_x == 1):\n",
    "        print(\"Couldn't get Metadata with method 2\")\n",
    "\n",
    "    return float(physical_size_x), float(physical_size_y)\n",
    "\n",
    "def get_physical(image_path):\n",
    "    physical_size_x = 1\n",
    "    physical_size_y = 1\n",
    "    try:\n",
    "        # Retrieve metadata\n",
    "        metadata = iio.immeta(image_path)\n",
    "\n",
    "        # Debugging output to understand metadata structure\n",
    "        #print(f\"Metadata for {image_path}: {metadata}\")\n",
    "\n",
    "        # Ensure the 'pixelsizex' and 'pixelsizey' keys are present in the metadata\n",
    "        physical_size_x = metadata.get('pixelsizex', 'N/A')\n",
    "        physical_size_y = metadata.get('pixelsizey', 'N/A')\n",
    "\n",
    "        # Check if the physical sizes are retrieved correctly\n",
    "        if physical_size_x == 'N/A' or physical_size_y == 'N/A':\n",
    "            physical_size_x = 1\n",
    "            physical_size_y = 1\n",
    "        else :\n",
    "            physical_size_x = float(physical_size_x) * 10**6\n",
    "            physical_size_y = float(physical_size_y) * 10**6\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'Failed to retrieve metadata from {image_path}: {e}')\n",
    "\n",
    "    if (physical_size_x == 1):\n",
    "        print(\"Couldn't get Metadata with method 1\")\n",
    "\n",
    "    return physical_size_x, physical_size_y\n",
    "\n",
    "def create_coco_json(images_data, annotations, categories, output_file): #Creates a COCO.json file that allows user to edit annotations else where\n",
    "    coco_json = {\n",
    "        \"info\": {\n",
    "            \"description\": \"Coral Areas\",\n",
    "            \"url\": \"https://drive.google.com/drive/folders/1I2PxS79XVj3VTLM-lKzeGh2WqyUNf9IB?usp=sharing\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"year\": 2024,\n",
    "            \"contributor\": \"Richard Zhao, Eric Su, Simon Zhao, Tracy Chen\",\n",
    "            \"date_created\": \"2024-07-25\"\n",
    "        },\n",
    "        \"licenses\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
    "                \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
    "            }\n",
    "        ],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": categories\n",
    "    }\n",
    "\n",
    "    for image in images_data:\n",
    "        image_info = {\n",
    "            \"id\": image[\"id\"],\n",
    "            \"license\": image[\"license\"],\n",
    "            \"file_name\": image[\"file_name\"],\n",
    "            \"width\": image[\"width\"],\n",
    "            \"height\": image[\"height\"],\n",
    "            \"date_captured\": image[\"date_captured\"]\n",
    "        }\n",
    "        coco_json[\"images\"].append(image_info)\n",
    "\n",
    "    for annotation in annotations:\n",
    "        annotation_info = {\n",
    "            \"id\": annotation[\"id\"],\n",
    "            \"image_id\": annotation[\"image_id\"],\n",
    "            \"category_id\": annotation[\"category_id\"],\n",
    "            \"bbox\": annotation[\"bbox\"],\n",
    "            \"area\": annotation[\"area\"],\n",
    "            \"segmentation\": annotation[\"segmentation\"],\n",
    "            \"iscrowd\": annotation[\"iscrowd\"]\n",
    "        }\n",
    "        coco_json[\"annotations\"].append(annotation_info)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(coco_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_block1(image_path): #Opens the image and returns the bounding box\n",
    "    image = Image.open(image_path)\n",
    "    image_np = np.array(image)\n",
    "    height, width, channels = image_np.shape\n",
    "    model = YOLO(\"C:/Users/richa_0/Documents/Coral Research/Machine Learning Models/V1 Models/2612.yolov8/results/50_epochs-/weights/best.pt\")\n",
    "    results = model.predict(image, verbose=False)\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "    if boxes.xyxy.tolist():\n",
    "        bbox = boxes.xyxy.tolist()[0]\n",
    "        class_ids = boxes.cls.tolist()\n",
    "        classes = [model.names[int(cls_id)] for cls_id in class_ids]\n",
    "    else:\n",
    "        bbox = [0, width, 0, height]\n",
    "    return image, bbox, classes\n",
    "\n",
    "def execute_block2(image, bbox, classes): #Gets the mask using the image and the bounding box\n",
    "    predictor = SamPredictor(sam)\n",
    "    predictor.set_image(np.array(image))\n",
    "    input_box = np.array(bbox)\n",
    "    center = [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2]\n",
    "    top_mid = [(bbox[0] + bbox[2]) / 2, bbox[1]]\n",
    "    bottom_mid =[(bbox[0] + bbox[2]) / 2, bbox[3]]\n",
    "    left_mid = [bbox[0], (bbox[1] + bbox[3]) / 2]\n",
    "    right_mid = [bbox[2], (bbox[1] + bbox[3]) / 2]\n",
    "    \"\"\"\n",
    "    if len(classes) > 0 and classes[0] == 'early-recruits':\n",
    "        input_point = np.array([center, top_mid, bottom_mid, left_mid, right_mid])\n",
    "        input_label = np.array([1, 0, 0, 0, 0])\n",
    "    else:\n",
    "        input_point = np.array([center])\n",
    "        input_label = np.array([1])\n",
    "    \"\"\"\n",
    "    input_point = np.array([center])\n",
    "    input_label = np.array([1])\n",
    "    masks, _, _ = predictor.predict(\n",
    "        point_coords=input_point,\n",
    "        point_labels=input_label,\n",
    "        box=input_box[None, :],\n",
    "        multimask_output=False,\n",
    "    )\n",
    "    return masks\n",
    "\n",
    "def execute_block3(image, bbox, masks, annotated_path, index, image_path): #Saves the images into the defined path, and gets the amount of pixels in the mask\n",
    "    pixels = get_area(masks[0])\n",
    "    pixel_size_x, pixel_size_y = get_physical(image_path)\n",
    "    if (pixel_size_x == 1):\n",
    "        pixel_size_x, pixel_size_y = get_physical_tag(image)\n",
    "    area = pixel_size_x * pixel_size_y * pixels\n",
    "    segmentation = mask_to_polygon(masks[0])\n",
    "    image_file = os.path.basename(annotated_path)\n",
    "    input_box = np.array(bbox)\n",
    "    image_np = np.array(image)\n",
    "    height, width, channels = image_np.shape\n",
    "    scale_factor = 100\n",
    "    fig, ax = plt.subplots(figsize=(width / scale_factor, height / scale_factor))\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, aspect='auto')\n",
    "    #show_mask(masks[0], ax) #for debbuging purposes\n",
    "    show_box(input_box, ax) #for debbuging purposes\n",
    "    show_polygon(segmentation, ax)\n",
    "    show_ground_truth(area, ax)\n",
    "    fig.savefig(annotated_path, dpi=100)\n",
    "    plt.close(fig)\n",
    "\n",
    "    image_info = {\n",
    "        \"id\": index,\n",
    "        \"license\": 1,\n",
    "        \"file_name\": image_file,\n",
    "        \"height\": height,\n",
    "        \"width\": width,\n",
    "        \"date_captured\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "    annotation_info = {\n",
    "        \"id\": index,\n",
    "        \"image_id\": index,\n",
    "        \"category_id\": 1,\n",
    "        \"bbox\": bbox,\n",
    "        \"area\": pixels,\n",
    "        \"segmentation\": segmentation,\n",
    "        \"iscrowd\": 0\n",
    "    }\n",
    "\n",
    "    return pixels, image_info, annotation_info, area, pixel_size_x, pixel_size_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Important Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_read_paths = [\n",
    "    \"C:/Users/richa_0/Documents/Coral Research/Testing/\",\n",
    "]\n",
    "folder_write_path = \"C:/Users/richa_0/Documents/Coral Research/Code Output/\"\n",
    "csv_path = folder_write_path + \"coral_areas_output.csv\"\n",
    "columns = [\"Folder\", \"Image Name\", \"Class\", \"Pixel Area\", \"Pixel Size X\", \"Pixel Size Y\", \"µm^2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Area Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't get Metadata with method 1\n",
      "Couldn't get Metadata with method 2\n",
      "Folder: Testing\n",
      "Image Name: 103_3_20231121.tif\n",
      "Class: early-recruits\n",
      "Bounding Box: [836.4700317382812, 648.7477416992188, 1069.192138671875, 859.3428955078125]\n",
      "Pixels: 34959\n",
      "Pixel Size X: 1.0\n",
      "Pixel Size Y: 1.0\n",
      "Area: 34959.0 µm^2\n",
      "\n",
      "Couldn't get Metadata with method 1\n",
      "Couldn't get Metadata with method 2\n",
      "Folder: Testing\n",
      "Image Name: 124_3_20231121.tif\n",
      "Class: early-recruits\n",
      "Bounding Box: [999.4439697265625, 612.2680053710938, 1304.1834716796875, 900.001953125]\n",
      "Pixels: 62898\n",
      "Pixel Size X: 1.0\n",
      "Pixel Size Y: 1.0\n",
      "Area: 62898.0 µm^2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique_folder_names = {}\n",
    "\n",
    "for index, folder in enumerate(folder_read_paths):\n",
    "    images_data = []\n",
    "    annotations = []\n",
    "    categories = [\n",
    "        {\"id\":0,\"name\":\"coral\",\"supercategory\":\"none\"},\n",
    "        {\"id\":1,\"name\":\"coral\",\"supercategory\":\"coral\"}\n",
    "    ]\n",
    "    folder_name = os.path.basename(folder.rstrip('/'))\n",
    "\n",
    "    if folder_name in unique_folder_names:\n",
    "        unique_folder_names[folder_name] += 1\n",
    "        new_folder_name = f\"{folder_name}_{unique_folder_names[folder_name]}\"\n",
    "    else:\n",
    "        unique_folder_names[folder_name] = 1\n",
    "        new_folder_name = folder_name\n",
    "\n",
    "    new_folder_path = os.path.join(folder_write_path, new_folder_name)\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "\n",
    "    json_path = os.path.join(new_folder_path, \"_annotations.coco.json\")\n",
    "\n",
    "    image_index = 0\n",
    "    for image_file in os.listdir(folder):\n",
    "        if image_file.endswith('.tif'):\n",
    "            image_path = os.path.join(folder, image_file)\n",
    "            base_name, _ = os.path.splitext(image_file)\n",
    "            image_file_png = base_name + \".png\"\n",
    "            annotated_path = os.path.join(new_folder_path, image_file_png)\n",
    "            image, bbox, classes = execute_block1(image_path)\n",
    "            masks = execute_block2(image, bbox, classes)\n",
    "            pixels, image_info, annotation_info, area, pixel_size_x, pixel_size_y = execute_block3(image, bbox, masks, annotated_path, image_index, image_path)\n",
    "            images_data.append(image_info)\n",
    "            annotations.append(annotation_info)\n",
    "            new_row = {\n",
    "                \"Folder\": new_folder_name,\n",
    "                \"Image Name\": image_file,\n",
    "                \"Class\": classes[0] if classes else \"No Class Detected\",  # Default to a string if classes is empty\n",
    "                \"Pixel Area\": pixels,\n",
    "                \"Pixel Size X\": pixel_size_x,\n",
    "                \"Pixel Size Y\": pixel_size_y,\n",
    "                \"µm^2\": area\n",
    "            }\n",
    "            new_row_df = pd.DataFrame([new_row], columns=columns)\n",
    "            new_row_df.to_csv(csv_path, mode='a', header=not os.path.exists(csv_path), index=False)\n",
    "            print(\n",
    "                \"Folder: \" + new_folder_name + \"\\n\" +\n",
    "                \"Image Name: \" + image_file + \"\\n\" +\n",
    "                \"Class: \" + (str(classes[0]) if classes else \"No Class Detected\") + \"\\n\" +\n",
    "                \"Bounding Box: \" + str(bbox) + \"\\n\" +\n",
    "                \"Pixels: \" + str(pixels) + \"\\n\" +\n",
    "                \"Pixel Size X: \" + str(pixel_size_x) + \"\\n\" +\n",
    "                \"Pixel Size Y: \" + str(pixel_size_y) + \"\\n\" +\n",
    "                \"Area: \" + str(area) + \" µm^2\" + \"\\n\"\n",
    "            )\n",
    "            image_index += 1\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    create_coco_json(images_data, annotations, categories, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
