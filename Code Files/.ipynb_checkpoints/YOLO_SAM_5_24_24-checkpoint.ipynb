{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup up CUDA for PyTorch\n",
    "#### *Must download CUDA drive from https://developer.nvidia.com/cuda-downloads and make a venv after in anaconda, not before. Then run the kernel below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHn6z4moM24T",
    "outputId": "b04ddf72-2f9f-44cb-9c45-66c7fbfd30d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (2.2.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (0.17.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (2.2.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: requests in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\richa_0\\anaconda3\\envs\\coral_research\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHn6z4moM24T",
    "outputId": "b04ddf72-2f9f-44cb-9c45-66c7fbfd30d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  3 11:27:38 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.23                 Driver Version: 551.23         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   62C    P8             18W /   81W |     786MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      4964    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     15004    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     18952    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19284    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     26312    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     27980    C+G   ...a\\Local\\slack\\app-4.37.98\\slack.exe      N/A      |\n",
      "|    0   N/A  N/A     28696    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     29920    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup RoboFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install roboflow --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QqaZoirGcrf"
   },
   "source": [
    "## Setup SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAxjKnlkO5bh",
    "outputId": "3d2788a7-e1fd-417c-c30d-22660b7a819a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
      "  Cloning https://github.com/facebookresearch/segment-anything.git to c:\\users\\richa_0\\appdata\\local\\temp\\pip-req-build-q5ostivs\n",
      "  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: segment-anything\n",
      "  Building wheel for segment-anything (setup.py): started\n",
      "  Building wheel for segment-anything (setup.py): finished with status 'done'\n",
      "  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36830 sha256=6bd36929ca9babdebffb454221eb495d81a78e706933e227f5d90e015010e448\n",
      "  Stored in directory: C:\\Users\\richa_0\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-c_kn2u_r\\wheels\\10\\cf\\59\\9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n",
      "Successfully built segment-anything\n",
      "Installing collected packages: segment-anything\n",
      "Successfully installed segment-anything-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git 'C:\\Users\\richa_0\\AppData\\Local\\Temp\\pip-req-build-q5ostivs'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/facebookresearch/segment-anything.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjPaUgCCO_UN",
    "outputId": "606039a4-7f7a-4306-ffca-a8ff66eab626"
   },
   "outputs": [],
   "source": [
    "!pip install -q  supervision jupyter_bbox_widget roboflow dataclasses-json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeRZ2RiwGzz7"
   },
   "source": [
    "#### Download SAM weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvmFI-e1PjE6",
    "outputId": "45fec68c-9423-4b1a-c0a9-cd4ab61754af"
   },
   "outputs": [],
   "source": [
    "!curl -O https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ks5PKNw_G8dh"
   },
   "source": [
    "## Setup Computer and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwLbgdDVQhMS",
    "outputId": "003cd6b8-24e8-47e3-981b-5e1c21bf6b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0+cu118\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"vit_h\"\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor # r\"C:\\Users\\richa_0\\Downloads\\sam_model_epoch_24.pth\"\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=r\"C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\sam_vit_h_4b8939.pth\").to(device=DEVICE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=\"SsfDz85MaMV4PPpSPJLO\")\n",
    "project = rf.workspace().project(\"coral-finder\")\n",
    "model = project.version(3).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVMUpajOHV9l"
   },
   "source": [
    "#### Add more dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5hFeInNqGCgg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches \n",
    "import torchvision\n",
    "import os\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import supervision as sv\n",
    "from roboflow import Roboflow\n",
    "import imageio.v3 as iio\n",
    "import datetime\n",
    "import json\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Custom YOLO V8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "model = YOLO('yolov8n.pt')\n",
    "name = \"50_epochs-\"\n",
    "project = \"C:/Users/richa_0/Documents/Coral Research/Machine Learning Models/1745_Grey-Scale.yolov8/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.76 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.11 ðŸš€ Python-3.10.13 torch-2.2.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Ti Laptop GPU, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Adjusted.yolov8\\data.yaml, epochs=50, time=None, patience=0, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=C:/Users/richa_0/Documents/Coral Research/Machine Learning Models/1745_Grey-Scale.yolov8/results, name=50_epochs-, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Grey-Scale.yolov8\\results\\50_epochs-\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Adjusted.yolov8\\train\\labels... 1181 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1181/1181 [00:01<00:00, 612.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Adjusted.yolov8\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Adjusted.yolov8\\valid\\labels... 282 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 282/282 [00:00<00:00, 638.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Adjusted.yolov8\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Grey-Scale.yolov8\\results\\50_epochs-\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Grey-Scale.yolov8\\results\\50_epochs-\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      3.55G      0.908      1.922      1.248          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:19<00:00, 15.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 16.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.877      0.824      0.959      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      3.55G     0.9018      1.366      1.226          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:17<00:00, 16.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 18.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.965      0.956      0.988      0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      3.55G     0.9393       1.16      1.242          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:17<00:00, 16.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282       0.96      0.909      0.979      0.774\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      3.55G     0.9074      1.015      1.212          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:16<00:00, 17.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282       0.92      0.887      0.961      0.642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      3.55G     0.8952     0.8798      1.206          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:17<00:00, 17.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 22.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.979      0.946      0.986      0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      3.55G     0.8703     0.8131      1.187          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:17<00:00, 17.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 21.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.973      0.934      0.986      0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      3.55G     0.8434     0.7765      1.173          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:16<00:00, 17.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 20.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.957        0.9      0.979      0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      3.55G     0.8388     0.7149      1.166          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:16<00:00, 18.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 21.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.962      0.948      0.987      0.839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      3.55G     0.8292     0.7106      1.152          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:17<00:00, 16.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282       0.94      0.938      0.988      0.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      3.55G     0.8021     0.6762      1.154          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:18<00:00, 15.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 20.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.967      0.966      0.993      0.857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      3.55G     0.7994     0.6473      1.142          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:22<00:00, 13.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.982      0.934      0.992      0.853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      3.55G     0.7977      0.642      1.146          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.962      0.933       0.98      0.827\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      3.55G     0.7734      0.628       1.13          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:22<00:00, 13.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.973      0.969      0.993      0.847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      3.55G      0.755     0.6135      1.119          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.934      0.943      0.992      0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      3.55G     0.7739     0.6336      1.139          0        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282       0.97      0.938      0.992      0.866\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      3.55G     0.7323     0.5983      1.108          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:19<00:00, 15.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.971      0.973       0.99      0.853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      3.55G     0.7326     0.5871      1.104          0        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.991      0.975      0.994      0.868\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      3.55G       0.72     0.5739      1.111          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 20.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.953      0.972      0.994      0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      3.55G     0.7204     0.5676      1.109          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.941       0.95      0.993      0.876\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      3.55G     0.7008     0.5509      1.095          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:21<00:00, 13.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.971      0.973      0.994       0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      3.55G     0.7133     0.5343      1.098          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:21<00:00, 13.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.948      0.944      0.991      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      3.55G      0.715     0.5417      1.092          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:22<00:00, 13.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 18.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.973      0.979      0.994      0.879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      3.55G     0.6949     0.5441      1.079          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:19<00:00, 15.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282       0.96      0.975      0.993      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      3.55G     0.6917      0.518      1.077          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:21<00:00, 13.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.976      0.976      0.994      0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      3.55G     0.7178     0.5541      1.104          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:22<00:00, 12.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.975      0.976      0.994      0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      3.55G      0.688     0.4942      1.084          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:21<00:00, 13.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.961      0.958      0.993       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      3.55G     0.6801     0.5157      1.082          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 17.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.968      0.981      0.993      0.899\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      3.55G     0.6941     0.4946       1.09          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 18.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.943      0.958      0.993      0.891\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      3.55G     0.6676     0.4789      1.063          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:21<00:00, 13.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.956      0.957      0.993      0.883\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      3.55G     0.6572     0.4481      1.056          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:21<00:00, 13.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 16.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.983      0.982      0.994       0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      3.55G     0.6553     0.4717      1.069          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 17.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282       0.97      0.972      0.993      0.896\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      3.55G      0.645     0.4813      1.055          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.949      0.963      0.993      0.903\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      3.55G     0.6426     0.4548      1.064          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.973      0.983      0.994      0.908\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      3.55G      0.645     0.4516      1.063          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.976      0.979      0.994      0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      3.55G     0.6466     0.4443       1.07          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:19<00:00, 15.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282       0.98      0.978      0.993      0.908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      3.55G      0.648     0.4454      1.063          4        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:19<00:00, 14.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 18.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.972      0.974      0.994      0.901\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      3.55G     0.6289     0.4343      1.064          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 16.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.984      0.975      0.994      0.901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      3.55G     0.6097     0.4331      1.046          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:21<00:00, 13.90it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.969      0.984      0.994        0.9\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      3.55G     0.6178      0.434      1.043          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282       0.96      0.975      0.993      0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      3.55G      0.603     0.4202      1.034          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:21<00:00, 13.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.977      0.971      0.994        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      3.55G      0.537     0.3621     0.9793          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:18<00:00, 15.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 20.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282       0.98      0.965      0.994      0.902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      3.55G     0.5301     0.3542      0.981          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:17<00:00, 16.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 20.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.962      0.981      0.993        0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      3.55G     0.5276       0.34     0.9853          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:18<00:00, 16.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.967      0.971      0.994      0.902\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      3.55G     0.5217     0.3503     0.9805          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:19<00:00, 15.28it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 17.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.973      0.986      0.994      0.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      3.55G     0.5151     0.3262     0.9765          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:18<00:00, 15.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 18.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.972      0.975      0.994      0.904\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      3.55G     0.5097     0.3103     0.9698          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 18.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.983      0.981      0.994      0.915\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      3.55G     0.4954     0.3104     0.9583          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:19<00:00, 14.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 20.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.982      0.979      0.995      0.915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      3.55G     0.4961      0.302     0.9649          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.976      0.987      0.994      0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      3.55G     0.4915      0.302     0.9529          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:02<00:00, 17.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282       0.98      0.979      0.994      0.911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      3.55G     0.4837     0.2892     0.9521          1        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296/296 [00:20<00:00, 14.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.979      0.977      0.994      0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.323 hours.\n",
      "Optimizer stripped from C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Grey-Scale.yolov8\\results\\50_epochs-\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Grey-Scale.yolov8\\results\\50_epochs-\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Grey-Scale.yolov8\\results\\50_epochs-\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.11 ðŸš€ Python-3.10.13 torch-2.2.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Ti Laptop GPU, 8192MiB)\n",
      "Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:01<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        282        282      0.982      0.979      0.994      0.915\n",
      "        early-recruits        282        210      0.989      0.957      0.994      0.865\n",
      "         late-recruits        282         72      0.975          1      0.995      0.965\n",
      "Speed: 0.2ms preprocess, 1.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Grey-Scale.yolov8\\results\\50_epochs-\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(data=r\"C:\\Users\\richa_0\\Documents\\Coral Research\\Machine Learning Models\\1745_Adjusted.yolov8\\data.yaml\",\n",
    "                      project=project,\n",
    "                      name=name,\n",
    "                      epochs=50,\n",
    "                      patience=0, #I am setting patience=0 to disable early stopping.\n",
    "                      batch=4,\n",
    "                      imgsz=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.2]) #0.6\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_points(coords, labels, ax, marker_size=375): #Extra method for the SAM inputs that we don't use\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "\n",
    "def show_box(box, ax): #For debugging purposes to check if YOLO V8 is working\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    rect = plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "def get_area(mask): #Prints the mask onto the image in a blue color\n",
    "    true_count = np.count_nonzero(mask)\n",
    "    return true_count\n",
    "\n",
    "def mask_to_polygon(mask):\n",
    "    # Convert mask to binary if it is not already\n",
    "    if mask.max() > 1:\n",
    "        _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    else:\n",
    "        binary_mask = (mask * 255).astype(np.uint8)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    polygons = []\n",
    "    for contour in contours:\n",
    "        # Simplify the contour to reduce the number of points\n",
    "        epsilon = 0.001 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        \n",
    "        # Extract points and flatten the list\n",
    "        polygon = approx.reshape(-1, 2).tolist()\n",
    "        flat_polygon = [point for sublist in polygon for point in sublist]\n",
    "        polygons.append(flat_polygon)\n",
    "    \n",
    "    return polygons\n",
    "\n",
    "def get_physical_tag(image): #Gets the physical conversion ratios through a library\n",
    "    physical_size_x = 1\n",
    "    physical_size_y = 1\n",
    "    exifdata = image.getexif()\n",
    "    for tagid in exifdata:\n",
    "        tagname = TAGS.get(tagid, tagid)\n",
    "        if tagname == \"ImageDescription\":\n",
    "            try:\n",
    "                value = exifdata.get(tagid)\n",
    "                start_index_x = value.find('PhysicalSizeX=\"') + len('PhysicalSizeX=\"')\n",
    "                end_index_x = value.find('\"', start_index_x)\n",
    "                physical_size_x = value[start_index_x:end_index_x]\n",
    "                start_index_x_unit = value.find('PhysicalSizeXUnit=\"') + len('PhysicalSizeXUnit=\"')\n",
    "                end_index_x_unit = value.find('\"', start_index_x_unit)\n",
    "                physical_size_x_unit = value[start_index_x_unit:end_index_x_unit]\n",
    "                start_index_y = value.find('PhysicalSizeY=\"') + len('PhysicalSizeY=\"')\n",
    "                end_index_y = value.find('\"', start_index_y)\n",
    "                physical_size_y = value[start_index_y:end_index_y]\n",
    "                start_index_y_unit = value.find('PhysicalSizeYUnit=\"') + len('PhysicalSizeYUnit=\"')\n",
    "                end_index_y_unit = value.find('\"', start_index_y_unit)\n",
    "                physical_size_y_unit = value[start_index_y_unit:end_index_y_unit]\n",
    "            except Exception as e:\n",
    "                print(f'Failed to process {image}: {e}')\n",
    "                continue\n",
    "    return float(physical_size_x), float(physical_size_y)\n",
    "\n",
    "def get_physical(image_path):\n",
    "    physical_size_x = 1\n",
    "    physical_size_y = 1\n",
    "    try:\n",
    "        # Retrieve metadata\n",
    "        metadata = iio.immeta(image_path)\n",
    "\n",
    "        # Debugging output to understand metadata structure\n",
    "        print(f\"Metadata for {image_path}: {metadata}\")\n",
    "        \n",
    "        # Ensure the 'pixelsizex' and 'pixelsizey' keys are present in the metadata\n",
    "        physical_size_x = metadata.get('pixelsizex', 'N/A')\n",
    "        physical_size_y = metadata.get('pixelsizey', 'N/A')\n",
    "\n",
    "        # Check if the physical sizes are retrieved correctly\n",
    "        if physical_size_x == 'N/A' or physical_size_y == 'N/A':\n",
    "            physical_size_x = 1\n",
    "            physical_size_y = 1\n",
    "\n",
    "        # Convert to micrometers\n",
    "        physical_size_x = float(physical_size_x) * 10**6\n",
    "        physical_size_y = float(physical_size_y) * 10**6\n",
    "    except Exception as e:\n",
    "        print(f'Failed to retrieve metadata from {image_path}: {e}')\n",
    "    \n",
    "    return float(physical_size_x), float(physical_size_y)\n",
    "\n",
    "def create_coco_json(images_data, annotations, categories, output_file): #Creates a COCO.json file that allows user to edit annotations else where\n",
    "    coco_json = {\n",
    "        \"info\": {\n",
    "            \"description\": \"Coral Areas\",\n",
    "            \"url\": \"https://drive.google.com/drive/folders/1I2PxS79XVj3VTLM-lKzeGh2WqyUNf9IB?usp=sharing\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"year\": 2024,\n",
    "            \"contributor\": \"Richard Zhao, Eric Su, Simon Zhao, Tracy Chen\",\n",
    "            \"date_created\": \"2024-07-25\"\n",
    "        },\n",
    "        \"licenses\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
    "                \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
    "            }\n",
    "        ],\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": categories\n",
    "    }\n",
    "\n",
    "    for image in images_data:\n",
    "        image_info = {\n",
    "            \"id\": image[\"id\"],\n",
    "            \"license\": image[\"license\"],\n",
    "            \"file_name\": image[\"file_name\"],\n",
    "            \"width\": image[\"width\"],\n",
    "            \"height\": image[\"height\"],\n",
    "            \"date_captured\": image[\"date_captured\"]\n",
    "        }\n",
    "        coco_json[\"images\"].append(image_info)\n",
    "\n",
    "    for annotation in annotations:\n",
    "        annotation_info = {\n",
    "            \"id\": annotation[\"id\"],\n",
    "            \"image_id\": annotation[\"image_id\"],\n",
    "            \"category_id\": annotation[\"category_id\"],\n",
    "            \"bbox\": annotation[\"bbox\"],\n",
    "            \"area\": annotation[\"area\"],\n",
    "            \"segmentation\": annotation[\"segmentation\"],\n",
    "            \"iscrowd\": annotation[\"iscrowd\"]\n",
    "        }\n",
    "        coco_json[\"annotations\"].append(annotation_info)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(coco_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_block1(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image_np = np.array(image)\n",
    "    height, width, channels = image_np.shape\n",
    "    model = YOLO(\"C:/Users/richa_0/Documents/Coral Research/Machine Learning Models/1745_Adjusted.yolov8/results/50_epochs-/weights/best.pt\") #Coral_Area_Generator_V1.yolov8\n",
    "    results = model.predict(image, verbose=False)\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "    if boxes.xyxy.tolist():\n",
    "        bbox = boxes.xyxy.tolist()[0]\n",
    "    else:\n",
    "        bbox = [0, width, 0, height]\n",
    "    return image, bbox\n",
    "\n",
    "def execute_block2(image, bbox):\n",
    "    predictor = SamPredictor(sam)\n",
    "    predictor.set_image(np.array(image))\n",
    "    input_box = np.array(bbox)\n",
    "    masks, _, _ = predictor.predict(\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        box=input_box[None, :],\n",
    "    multimask_output=False,\n",
    "    )\n",
    "    return masks\n",
    "\n",
    "def execute_block3(image, bbox, masks, annotated_path, index): #Saves the images into the defined path, and gets the amount of pixels in the mask\n",
    "    image_file = os.path.basename(annotated_path)\n",
    "    input_box = np.array(bbox)\n",
    "    image_np = np.array(image)\n",
    "    height, width, channels = image_np.shape\n",
    "    scale_factor = 100\n",
    "    fig, ax = plt.subplots(figsize=(width / scale_factor, height / scale_factor))\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, aspect='auto')\n",
    "    show_mask(masks[0], ax) #for debbuging purposes\n",
    "    show_box(input_box, ax) #for debbuging purposes\n",
    "    fig.savefig(annotated_path, dpi=100)\n",
    "    plt.close(fig)\n",
    "    pixels = get_area(masks[0])\n",
    "    segmentation = mask_to_polygon(masks[0])\n",
    "\n",
    "    image_info = {\n",
    "        \"id\": index,\n",
    "        \"license\": 1,\n",
    "        \"file_name\": image_file,\n",
    "        \"height\": height,\n",
    "        \"width\": width,\n",
    "        \"date_captured\": datetime.datetime.now().isoformat()\n",
    "    }\n",
    "    annotation_info = {\n",
    "        \"id\": index,\n",
    "        \"image_id\": index,\n",
    "        \"category_id\": 1,\n",
    "        \"bbox\": bbox,\n",
    "        \"area\": pixels,\n",
    "        \"segmentation\": segmentation,\n",
    "        \"iscrowd\": 0\n",
    "    }\n",
    "\n",
    "    return pixels, image_info, annotation_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Important Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_read_paths = [\n",
    "    \"C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/\"\n",
    "    #\"/content/gdrive/MyDrive/Coral Area Generator V1 Folder/1-100/\",\n",
    "    #\"/content/gdrive/MyDrive/Coral Area Generator V1 Folder/101-200/\",\n",
    "    #\"/content/gdrive/MyDrive/Coral Area Generator V1 Folder/201-300/\",\n",
    "    #\"/content/gdrive/MyDrive/Coral Area Generator V1 Folder/301-400/\",\n",
    "    #\"/content/gdrive/MyDrive/Coral Area Generator V1 Folder/401-500/\",\n",
    "    #\"/content/gdrive/MyDrive/Coral Area Generator V1 Folder/501-600/\",\n",
    "    #\"/content/gdrive/MyDrive/Coral Area Generator V1 Folder/601-700/\",\n",
    "    #\"/content/gdrive/MyDrive/Coral Area Generator V1 Folder/701-783/\"\n",
    "]\n",
    "folder_write_path = \"C:/Users/richa_0/Documents/Coral Research/Code Output/\"\n",
    "csv_path = folder_write_path + \"coral_areas_output.csv\"\n",
    "columns = [\"Folder\", \"Image Name\", \"Pixel Area\", \"Pixel Size X\", \"Pixel Size Y\", \"Âµm^2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Area Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve metadata from C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/CAB-T21-PSTR-002-E.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
      "Folder: Original_Raw_10-Blue_TIF\n",
      "Image Name: CAB-T21-PSTR-002-E.tif\n",
      "Bounding Box: [0, 1600, 0, 1200]\n",
      "Pixels: 10\n",
      "Pixel Size X: 5.234929078014185\n",
      "Pixel Size Y: 5.234929078014186\n",
      "Area: 274.04482451838453 Âµm^2\n",
      "\n",
      "Failed to retrieve metadata from C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/CAB-T21-PSTR-007-A.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
      "Folder: Original_Raw_10-Blue_TIF\n",
      "Image Name: CAB-T21-PSTR-007-A.tif\n",
      "Bounding Box: [0, 1600, 0, 1200]\n",
      "Pixels: 0\n",
      "Pixel Size X: 5.234929078014185\n",
      "Pixel Size Y: 5.234929078014186\n",
      "Area: 0.0 Âµm^2\n",
      "\n",
      "Failed to retrieve metadata from C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/CAB-T21-PSTR-012-A.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
      "Folder: Original_Raw_10-Blue_TIF\n",
      "Image Name: CAB-T21-PSTR-012-A.tif\n",
      "Bounding Box: [0, 1600, 0, 1200]\n",
      "Pixels: 0\n",
      "Pixel Size X: 4.762096774193548\n",
      "Pixel Size Y: 4.762096774193548\n",
      "Area: 0.0 Âµm^2\n",
      "\n",
      "Failed to retrieve metadata from C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/CAB-T28-CNAT-017-E.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
      "Folder: Original_Raw_10-Blue_TIF\n",
      "Image Name: CAB-T28-CNAT-017-E.tif\n",
      "Bounding Box: [0, 1600, 0, 1200]\n",
      "Pixels: 37\n",
      "Pixel Size X: 8.787202380952378\n",
      "Pixel Size Y: 8.787202380952378\n",
      "Area: 2856.9522503011603 Âµm^2\n",
      "\n",
      "Failed to retrieve metadata from C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/CAB-T28-PSTR-013-A.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
      "Folder: Original_Raw_10-Blue_TIF\n",
      "Image Name: CAB-T28-PSTR-013-A.tif\n",
      "Bounding Box: [255.11825561523438, 4.0724945068359375, 1453.079833984375, 1200.0]\n",
      "Pixels: 973383\n",
      "Pixel Size X: 8.787202380952378\n",
      "Pixel Size Y: 8.787202380952378\n",
      "Area: 75159696.00688903 Âµm^2\n",
      "\n",
      "Failed to retrieve metadata from C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/CRM-T21-CNAT-003-D.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
      "Folder: Original_Raw_10-Blue_TIF\n",
      "Image Name: CRM-T21-CNAT-003-D.tif\n",
      "Bounding Box: [502.91278076171875, 131.3043212890625, 1368.973876953125, 1066.3245849609375]\n",
      "Pixels: 635485\n",
      "Pixel Size X: 4.762096774193548\n",
      "Pixel Size Y: 4.762096774193548\n",
      "Area: 14411252.83046631 Âµm^2\n",
      "\n",
      "Failed to retrieve metadata from C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/CRM-T21-CNAT-004-A.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
      "Folder: Original_Raw_10-Blue_TIF\n",
      "Image Name: CRM-T21-CNAT-004-A.tif\n",
      "Bounding Box: [0, 1600, 0, 1200]\n",
      "Pixels: 33\n",
      "Pixel Size X: 6.834490740740739\n",
      "Pixel Size Y: 6.83449074074074\n",
      "Area: 1541.4387016139397 Âµm^2\n",
      "\n",
      "Failed to retrieve metadata from C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/DAB-T15-CNAT-017-C.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
      "Folder: Original_Raw_10-Blue_TIF\n",
      "Image Name: DAB-T15-CNAT-017-C.tif\n",
      "Bounding Box: [326.1347961425781, 92.42073059082031, 1570.126708984375, 1021.1785278320312]\n",
      "Pixels: 761723\n",
      "Pixel Size X: 2.1968005952380953\n",
      "Pixel Size Y: 2.1968005952380953\n",
      "Area: 3676024.0522907977 Âµm^2\n",
      "\n",
      "Failed to retrieve metadata from C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/DAB-T15-CNAT-024-B.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
      "Folder: Original_Raw_10-Blue_TIF\n",
      "Image Name: DAB-T15-CNAT-024-B.tif\n",
      "Bounding Box: [0, 1600, 0, 1200]\n",
      "Pixels: 32\n",
      "Pixel Size X: 2.1968005952380953\n",
      "Pixel Size Y: 2.1968005952380953\n",
      "Area: 154.4298513676304 Âµm^2\n",
      "\n",
      "Failed to retrieve metadata from C:/Users/richa_0/Documents/Coral Research/Images/Original_Raw_10-Blue_TIF/DAB-T15-PSTR-012-C.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
      "Folder: Original_Raw_10-Blue_TIF\n",
      "Image Name: DAB-T15-PSTR-012-C.tif\n",
      "Bounding Box: [0, 1600, 0, 1200]\n",
      "Pixels: 0\n",
      "Pixel Size X: 2.1968005952380953\n",
      "Pixel Size Y: 2.1968005952380953\n",
      "Area: 0.0 Âµm^2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, folder in enumerate(folder_read_paths):\n",
    "\n",
    "    images_data = []\n",
    "    annotations = []\n",
    "    categories = [\n",
    "        {\"id\":0,\"name\":\"coral\",\"supercategory\":\"none\"},\n",
    "        {\"id\":1,\"name\":\"coral\",\"supercategory\":\"coral\"}\n",
    "    ]\n",
    "    folder_name = os.path.basename(folder.rstrip('/'))\n",
    "\n",
    "    new_folder_path = os.path.join(folder_write_path, folder_name)\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "\n",
    "    json_path = os.path.join(new_folder_path, \"_annotations.coco.json\")\n",
    "    image_index = 0\n",
    "    for image_file in os.listdir(folder):\n",
    "        if image_file.endswith('.tif'):\n",
    "            image_path = os.path.join(folder, image_file)\n",
    "            base_name, _ = os.path.splitext(image_file)\n",
    "            image_file_png = base_name + \".png\"\n",
    "            annotated_path = os.path.join(new_folder_path, image_file_png)\n",
    "            image, bbox = execute_block1(image_path)\n",
    "            masks = execute_block2(image, bbox)\n",
    "            pixels, image_info, annotation_info = execute_block3(image, bbox, masks, annotated_path, image_index)\n",
    "            images_data.append(image_info)\n",
    "            annotations.append(annotation_info)\n",
    "            pixel_size_x, pixel_size_y = get_physical(image_path)\n",
    "            if (pixel_size_x == 1):\n",
    "                pixel_size_x, pixel_size_y = get_physical_tag(image)\n",
    "            area = pixel_size_x * pixel_size_y * pixels\n",
    "            new_row = {\"Folder\": folder_name, \"Image Name\": image_file, \"Pixel Area\": pixels, \"Pixel Size X\": pixel_size_x, \"Pixel Size Y\": pixel_size_y, \"Âµm^2\": area}\n",
    "            new_row_df = pd.DataFrame([new_row], columns=columns)\n",
    "            new_row_df.to_csv(csv_path, mode='a', header=not os.path.exists(csv_path), index=False)\n",
    "            print(\"Folder: \" + folder_name + \"\\n\" + \"Image Name: \" + image_file + \"\\n\" + \"Bounding Box: \" + str(bbox) + \"\\n\" + \"Pixels: \" + str(pixels) + \"\\n\" + \"Pixel Size X: \" + str(pixel_size_x) + \"\\n\" + \"Pixel Size Y: \" + str(pixel_size_y) + \"\\n\" + \"Area: \" + str(area) + \" Âµm^2\" + \"\\n\")\n",
    "            image_index += 1\n",
    "    \n",
    "    create_coco_json(images_data, annotations, categories, json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
