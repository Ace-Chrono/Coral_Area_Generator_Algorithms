{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxYds6JbNe33"
      },
      "source": [
        "# Coral Area Generator\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Dh_PdTNktL"
      },
      "source": [
        "## Download the this folder with specific formats and ml models into your google drive: https://drive.google.com/drive/folders/1I2PxS79XVj3VTLM-lKzeGh2WqyUNf9IB?usp=sharing\n",
        "\n",
        "## There is also a readme file to help initial users navigate this notebook more efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXq67C7XIcGV"
      },
      "source": [
        "## Install Dependencies and Libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/sam2.git\n",
        "%cd sam2\n",
        "!pip install -e . --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fp53jYwzgCor",
        "outputId": "21519673-4829-4caf-ebe9-5034e9b94a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sam2'...\n",
            "remote: Enumerating objects: 1070, done.\u001b[K\n",
            "remote: Total 1070 (delta 0), reused 0 (delta 0), pack-reused 1070 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1070/1070), 134.70 MiB | 16.62 MiB/s, done.\n",
            "Resolving deltas: 100% (375/375), done.\n",
            "/content/sam2\n",
            "Obtaining file:///content/sam2\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.20.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (4.67.1)\n",
            "Collecting hydra-core>=1.3.2 (from SAM-2==1.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting iopath>=0.1.10 (from SAM-2==1.0)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from SAM-2==1.0) (11.1.0)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->SAM-2==1.0)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->SAM-2==1.0)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->SAM-2==1.0) (24.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.10->SAM-2==1.0) (4.12.2)\n",
            "Collecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.5.1->SAM-2==1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.5.1->SAM-2==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.5.1->SAM-2==1.0) (1.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.5.1->SAM-2==1.0) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: SAM-2, antlr4-python3-runtime, iopath\n",
            "  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SAM-2: filename=SAM_2-1.0-0.editable-cp311-cp311-linux_x86_64.whl size=13739 sha256=5ac8669cc98badc5fb754cb10e6baa01c04315a921e42cc3e1566e0335033423\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n2x0b28u/wheels/76/dc/37/006d341f6080de50c00d031747ee8a1a03f3fb513175bce1c0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=618d482938ac5a1768dd78a8b2fc0387afe256c57bcdd3d2c025abcee53766ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31528 sha256=6bbf6ba062680735d13cdcf858bde986ac149f4ce6cc364d44988488cc74e785\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built SAM-2 antlr4-python3-runtime iopath\n",
            "Installing collected packages: antlr4-python3-runtime, portalocker, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, iopath, hydra-core, nvidia-cusolver-cu12, SAM-2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed SAM-2-1.0 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 iopath-0.1.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 portalocker-3.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "bbc117f7758e46788c54c098b2f3fcf5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58Zp9cPRZdkQ",
        "outputId": "073c7977-4d6a-4d25-a7f7-8277211f7a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.94-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.94-py3-none-any.whl (949 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.8/949.8 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.94 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94sOwWuWbjsj"
      },
      "source": [
        "## Run the Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTrDgvwP7iBM",
        "outputId": "df3e97c0-2e6d-45ad-cd79-3ae9012979bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Coral_Area_Generator.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile Coral_Area_Generator.py\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL.ExifTags import TAGS\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torchvision\n",
        "import os\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "from google.colab import drive, files\n",
        "import json\n",
        "import imageio.v3 as iio\n",
        "import datetime\n",
        "import cv2\n",
        "import gc\n",
        "import torch\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
        "drive.mount('/content/gdrive/')\n",
        "print(torch.__version__)\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(DEVICE)\n",
        "young_checkpoint = \"/content/gdrive/MyDrive/Coral Area Generator Folder/Machine Learning Models/best_V3_Young_SAM2.pth\"\n",
        "mature_checkpoint = \"/content/gdrive/MyDrive/Coral Area Generator Folder/Machine Learning Models/best_V3_Mature_SAM2.pth\"\n",
        "model_cfg = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
        "young_predictor = SAM2ImagePredictor(build_sam2(model_cfg, young_checkpoint))\n",
        "mature_predictor = SAM2ImagePredictor(build_sam2(model_cfg, mature_checkpoint))\n",
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.2]) #0.6\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375): #Extra method for the SAM inputs that we don't use\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax): #For debugging purposes to check if YOLO is working\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    rect = plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2)\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "def show_polygon(polygons, ax):\n",
        "    formatted_polygons = [np.array(polygon).reshape(-1, 2) for polygon in polygons]\n",
        "    for polygon in formatted_polygons:\n",
        "        polygon_patch = patches.Polygon(polygon, closed=True, edgecolor='red', facecolor=(0,0,0,0), lw=2)\n",
        "        ax.add_patch(polygon_patch)\n",
        "\n",
        "def show_ground_truth(area, ax):\n",
        "    ax.text(50, 50, str(area) + \" µm\", color='white', fontsize=16, backgroundcolor='black')\n",
        "\n",
        "def get_area(mask): #Prints the mask onto the image in a blue color\n",
        "    true_count = np.count_nonzero(mask)\n",
        "    return true_count\n",
        "\n",
        "def mask_to_polygon(mask):\n",
        "    # Convert mask to binary if it is not already\n",
        "    if mask.max() > 1:\n",
        "        _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "    else:\n",
        "        binary_mask = (mask * 255).astype(np.uint8)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    polygons = []\n",
        "    for contour in contours:\n",
        "        # Simplify the contour to reduce the number of points\n",
        "        epsilon = 0.001 * cv2.arcLength(contour, True)\n",
        "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "        # Extract points and flatten the list\n",
        "        polygon = approx.reshape(-1, 2).tolist()\n",
        "        flat_polygon = [point for sublist in polygon for point in sublist]\n",
        "        polygons.append(flat_polygon)\n",
        "\n",
        "    return polygons\n",
        "\n",
        "def get_physical_tag(image): #Gets the physical conversion ratios through a library\n",
        "    physical_size_x = 1\n",
        "    physical_size_y = 1\n",
        "    exifdata = image.getexif()\n",
        "    for tagid in exifdata:\n",
        "        tagname = TAGS.get(tagid, tagid)\n",
        "        if tagname == \"ImageDescription\":\n",
        "            try:\n",
        "                value = exifdata.get(tagid)\n",
        "                start_index_x = value.find('PhysicalSizeX=\"') + len('PhysicalSizeX=\"')\n",
        "                end_index_x = value.find('\"', start_index_x)\n",
        "                physical_size_x = value[start_index_x:end_index_x]\n",
        "                start_index_x_unit = value.find('PhysicalSizeXUnit=\"') + len('PhysicalSizeXUnit=\"')\n",
        "                end_index_x_unit = value.find('\"', start_index_x_unit)\n",
        "                physical_size_x_unit = value[start_index_x_unit:end_index_x_unit]\n",
        "                start_index_y = value.find('PhysicalSizeY=\"') + len('PhysicalSizeY=\"')\n",
        "                end_index_y = value.find('\"', start_index_y)\n",
        "                physical_size_y = value[start_index_y:end_index_y]\n",
        "                start_index_y_unit = value.find('PhysicalSizeYUnit=\"') + len('PhysicalSizeYUnit=\"')\n",
        "                end_index_y_unit = value.find('\"', start_index_y_unit)\n",
        "                physical_size_y_unit = value[start_index_y_unit:end_index_y_unit]\n",
        "            except Exception as e:\n",
        "                print(f'Failed to process {image}: {e}')\n",
        "                continue\n",
        "    return float(physical_size_x), float(physical_size_y)\n",
        "\n",
        "def get_physical(image_path):\n",
        "    physical_size_x = 1\n",
        "    physical_size_y = 1\n",
        "    try:\n",
        "        # Retrieve metadata\n",
        "        metadata = iio.immeta(image_path)\n",
        "\n",
        "        # Debugging output to understand metadata structure\n",
        "        print(f\"Metadata for {image_path}: {metadata}\")\n",
        "\n",
        "        # Ensure the 'pixelsizex' and 'pixelsizey' keys are present in the metadata\n",
        "        physical_size_x = metadata.get('pixelsizex', 'N/A')\n",
        "        physical_size_y = metadata.get('pixelsizey', 'N/A')\n",
        "\n",
        "        # Check if the physical sizes are retrieved correctly\n",
        "        if physical_size_x == 'N/A' or physical_size_y == 'N/A':\n",
        "            physical_size_x = 1\n",
        "            physical_size_y = 1\n",
        "        else :\n",
        "            physical_size_x = float(physical_size_x) * 10**6\n",
        "            physical_size_y = float(physical_size_y) * 10**6\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Failed to retrieve metadata from {image_path}: {e}')\n",
        "\n",
        "    return physical_size_x, physical_size_y\n",
        "\n",
        "def create_coco_json(images_data, annotations, categories, output_file): #Creates a COCO.json file that allows user to edit annotations else where\n",
        "    coco_json = {\n",
        "        \"info\": {\n",
        "            \"description\": \"Coral Areas\",\n",
        "            \"url\": \"https://drive.google.com/drive/folders/1I2PxS79XVj3VTLM-lKzeGh2WqyUNf9IB?usp=sharing\",\n",
        "            \"version\": \"1.0\",\n",
        "            \"year\": 2024,\n",
        "            \"contributor\": \"Richard Zhao, Eric Su, Simon Zhao, Tracy Chen\",\n",
        "            \"date_created\": \"2024-07-25\"\n",
        "        },\n",
        "        \"licenses\": [\n",
        "            {\n",
        "                \"id\": 1,\n",
        "                \"name\": \"Attribution-NonCommercial-ShareAlike License\",\n",
        "                \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
        "            }\n",
        "        ],\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": categories\n",
        "    }\n",
        "\n",
        "    for image in images_data:\n",
        "        image_info = {\n",
        "            \"id\": image[\"id\"],\n",
        "            \"license\": image[\"license\"],\n",
        "            \"file_name\": image[\"file_name\"],\n",
        "            \"width\": image[\"width\"],\n",
        "            \"height\": image[\"height\"],\n",
        "            \"date_captured\": image[\"date_captured\"]\n",
        "        }\n",
        "        coco_json[\"images\"].append(image_info)\n",
        "\n",
        "    for annotation in annotations:\n",
        "        annotation_info = {\n",
        "            \"id\": annotation[\"id\"],\n",
        "            \"image_id\": annotation[\"image_id\"],\n",
        "            \"category_id\": annotation[\"category_id\"],\n",
        "            \"bbox\": annotation[\"bbox\"],\n",
        "            \"area\": annotation[\"area\"],\n",
        "            \"segmentation\": annotation[\"segmentation\"],\n",
        "            \"iscrowd\": annotation[\"iscrowd\"]\n",
        "        }\n",
        "        coco_json[\"annotations\"].append(annotation_info)\n",
        "\n",
        "    with open(output_file, 'w') as f:\n",
        "        json.dump(coco_json, f, indent=4)\n",
        "\n",
        "def execute_block1(image_path): #Opens the image and returns the bounding box\n",
        "    image = Image.open(image_path)\n",
        "    image_np = np.array(image)\n",
        "    height, width, channels = image_np.shape\n",
        "    model = YOLO(\"/content/gdrive/MyDrive/Coral Area Generator Folder/Machine Learning Models/best.pt\")\n",
        "    results = model.predict(image, verbose=False)\n",
        "    classes = ['late-recruits']\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "    if boxes.xyxy.tolist():\n",
        "        bbox = boxes.xyxy.tolist()[0]\n",
        "        class_ids = boxes.cls.tolist()\n",
        "        classes = [model.names[int(cls_id)] for cls_id in class_ids]\n",
        "    else:\n",
        "        bbox = [0, width, 0, height]\n",
        "    return image, bbox, classes\n",
        "\n",
        "def execute_block2(image, bbox, classes): #Gets the mask using the image and the bounding box\n",
        "    input_box = np.array(bbox)\n",
        "    center = [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2]\n",
        "    top_mid = [(bbox[0] + bbox[2]) / 2, bbox[1]]\n",
        "    bottom_mid =[(bbox[0] + bbox[2]) / 2, bbox[3]]\n",
        "    left_mid = [bbox[0], (bbox[1] + bbox[3]) / 2]\n",
        "    right_mid = [bbox[2], (bbox[1] + bbox[3]) / 2]\n",
        "    if len(classes) > 0 and classes[0] == 'early-recruits':\n",
        "        input_point = np.array([center, top_mid, bottom_mid, left_mid, right_mid])\n",
        "        input_label = np.array([1, 0, 0, 0, 0])\n",
        "        with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "            young_predictor.set_image(np.array(image))\n",
        "            masks, _, _ = young_predictor.predict(\n",
        "                point_coords=input_point,\n",
        "                point_labels=input_label,\n",
        "                box=input_box[None, :],\n",
        "                multimask_output=False,\n",
        "            )\n",
        "    else:\n",
        "        input_point = np.array([center])\n",
        "        input_label = np.array([1])\n",
        "        with torch.inference_mode(), torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
        "            mature_predictor.set_image(np.array(image))\n",
        "            masks, _, _ = mature_predictor.predict(\n",
        "                point_coords=input_point,\n",
        "                point_labels=input_label,\n",
        "                box=input_box[None, :],\n",
        "                multimask_output=False,\n",
        "            )\n",
        "    return masks\n",
        "\n",
        "def execute_block3(image, bbox, masks, annotated_path, index, image_path): #Saves the images into the defined path, and gets the amount of pixels in the mask\n",
        "    pixels = get_area(masks[0])\n",
        "    pixel_size_x, pixel_size_y = get_physical(image_path)\n",
        "    if (pixel_size_x == 1):\n",
        "        pixel_size_x, pixel_size_y = get_physical_tag(image)\n",
        "    area = pixel_size_x * pixel_size_y * pixels\n",
        "    segmentation = mask_to_polygon(masks[0])\n",
        "    image_file = os.path.basename(annotated_path)\n",
        "    input_box = np.array(bbox)\n",
        "    image_np = np.array(image)\n",
        "    height, width, channels = image_np.shape\n",
        "    scale_factor = 100\n",
        "    fig, ax = plt.subplots(figsize=(width / scale_factor, height / scale_factor))\n",
        "    ax.set_position([0, 0, 1, 1])\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, aspect='auto')\n",
        "    if (vmask == \"y\"):\n",
        "        show_mask(masks[0], ax)\n",
        "    if (vbbox == \"y\"):\n",
        "        show_box(input_box, ax)\n",
        "    if (vpolygon == \"y\"):\n",
        "        show_polygon(segmentation, ax)\n",
        "    if (vground_truth == \"y\"):\n",
        "        show_ground_truth(area, ax)\n",
        "    fig.savefig(annotated_path, dpi=100)\n",
        "    plt.close(fig)\n",
        "\n",
        "    image_info = {\n",
        "        \"id\": index,\n",
        "        \"license\": 1,\n",
        "        \"file_name\": image_file,\n",
        "        \"height\": height,\n",
        "        \"width\": width,\n",
        "        \"date_captured\": datetime.datetime.now().isoformat()\n",
        "    }\n",
        "    annotation_info = {\n",
        "        \"id\": index,\n",
        "        \"image_id\": index,\n",
        "        \"category_id\": 1,\n",
        "        \"bbox\": bbox,\n",
        "        \"area\": pixels,\n",
        "        \"segmentation\": segmentation,\n",
        "        \"iscrowd\": 0\n",
        "    }\n",
        "\n",
        "    return pixels, image_info, annotation_info, area, pixel_size_x, pixel_size_y\n",
        "\n",
        "vmask = input(\"Show blue mask? (y/n): \")\n",
        "vbbox = input(\"Show bounding box? (y/n): \")\n",
        "vpolygon = input(\"Show polygon outline? (y/n): \")\n",
        "vground_truth = input(\"Show ground truth? (y/n): \")\n",
        "folder_read_paths = input(\"Enter file path(s) where your images are located separated by commas (Ex: /content/gdrive/MyDrive/Coral Area Generator Folder/Coral Recruit Images/, ...): \")\n",
        "folder_read_paths = [path.strip() for path in folder_read_paths.split(\",\")]\n",
        "folder_write_path = input(\"Enter file path where you want to output images (Ex: /content/gdrive/MyDrive/Coral Area Generator Folder/Code Output/): \")\n",
        "csv_path = folder_write_path + \"coral_areas_output.csv\"\n",
        "columns = [\"Folder\", \"Image Name\", \"Class\", \"Pixel Area\", \"Pixel Size X\", \"Pixel Size Y\", \"µm^2\"]\n",
        "unique_folder_names = {}\n",
        "\n",
        "for index, folder in enumerate(folder_read_paths):\n",
        "\n",
        "    images_data = []\n",
        "    annotations = []\n",
        "    categories = [\n",
        "        {\"id\":0,\"name\":\"coral\",\"supercategory\":\"none\"},\n",
        "        {\"id\":1,\"name\":\"coral\",\"supercategory\":\"coral\"}\n",
        "    ]\n",
        "    folder_name = os.path.basename(folder.rstrip('/'))\n",
        "\n",
        "    if folder_name in unique_folder_names:\n",
        "        unique_folder_names[folder_name] += 1\n",
        "        new_folder_name = f\"{folder_name}_{unique_folder_names[folder_name]}\"\n",
        "    else:\n",
        "        unique_folder_names[folder_name] = 0\n",
        "        new_folder_name = folder_name\n",
        "\n",
        "    new_folder_path = os.path.join(folder_write_path, folder_name)\n",
        "    if not os.path.exists(new_folder_path):\n",
        "        os.makedirs(new_folder_path)\n",
        "\n",
        "    json_path = os.path.join(new_folder_path, \"_annotations.coco.json\")\n",
        "\n",
        "    image_index = 0\n",
        "    for image_file in os.listdir(folder):\n",
        "        if image_file.endswith('.tif'):\n",
        "            image_path = os.path.join(folder, image_file)\n",
        "            base_name, _ = os.path.splitext(image_file)\n",
        "            image_file_png = base_name + \".png\"\n",
        "            annotated_path = os.path.join(new_folder_path, image_file_png)\n",
        "            image, bbox, classes = execute_block1(image_path)\n",
        "            masks = execute_block2(image, bbox, classes)\n",
        "            pixels, image_info, annotation_info, area, pixel_size_x, pixel_size_y= execute_block3(image, bbox, masks, annotated_path, image_index, image_path)\n",
        "            images_data.append(image_info)\n",
        "            annotations.append(annotation_info)\n",
        "            new_row = {\n",
        "                \"Folder\": new_folder_name,\n",
        "                \"Image Name\": image_file,\n",
        "                \"Class\": classes[0] if classes else \"No Class Detected\",  # Default to a string if classes is empty\n",
        "                \"Pixel Area\": pixels,\n",
        "                \"Pixel Size X\": pixel_size_x,\n",
        "                \"Pixel Size Y\": pixel_size_y,\n",
        "                \"µm^2\": area\n",
        "            }\n",
        "            new_row_df = pd.DataFrame([new_row], columns=columns)\n",
        "            new_row_df.to_csv(csv_path, mode='a', header=not os.path.exists(csv_path), index=False)\n",
        "            print(\n",
        "                \"Folder: \" + new_folder_name + \"\\n\" +\n",
        "                \"Image Name: \" + image_file + \"\\n\" +\n",
        "                \"Class: \" + (str(classes[0]) if classes else \"No Class Detected\") + \"\\n\" +\n",
        "                \"Bounding Box: \" + str(bbox) + \"\\n\" +\n",
        "                \"Pixels: \" + str(pixels) + \"\\n\" +\n",
        "                \"Pixel Size X: \" + str(pixel_size_x) + \"\\n\" +\n",
        "                \"Pixel Size Y: \" + str(pixel_size_y) + \"\\n\" +\n",
        "                \"Area: \" + str(area) + \" µm^2\" + \"\\n\"\n",
        "            )\n",
        "            image_index += 1\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    create_coco_json(images_data, annotations, categories, json_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEQVJeuFUnjG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "f26e98a2-cda3-415b-8865-e96c096ff8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Mounted at /content/gdrive/\n",
            "2.6.0+cu124\n",
            "cuda:0\n",
            "Show blue mask? (y/n): n\n",
            "Show bounding box? (y/n): y\n",
            "Show polygon outline? (y/n): y\n",
            "Show ground truth? (y/n): y\n",
            "Enter file path(s) where your images are located separated by commas (Ex: /content/gdrive/MyDrive/Coral Area Generator Folder/Coral Recruit Images/, ...): /content/gdrive/MyDrive/Coral Area Generator Folder/Coral Recruit Images/,\n",
            "Enter file path where you want to output images (Ex: /content/gdrive/MyDrive/Coral Area Generator Folder/Code Output/): /content/gdrive/MyDrive/Coral Area Generator Folder/Code Output/\n",
            "Failed to retrieve metadata from /content/gdrive/MyDrive/Coral Area Generator Folder/Coral Recruit Images/108_2_20230925_m.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
            "Folder: Coral Recruit Images\n",
            "Image Name: 108_2_20230925_m.tif\n",
            "Class: early-recruits\n",
            "Bounding Box: [815.6358642578125, 613.08056640625, 1185.674560546875, 943.1243286132812]\n",
            "Pixels: 87614\n",
            "Pixel Size X: 2.1589113817403494\n",
            "Pixel Size Y: 2.1589113817403494\n",
            "Area: 408359.9484055818 µm^2\n",
            "\n",
            "Failed to retrieve metadata from /content/gdrive/MyDrive/Coral Area Generator Folder/Coral Recruit Images/139_2_20240305_m.tif: dictionary update sequence element #0 has length 1; 2 is required\n",
            "Folder: Coral Recruit Images\n",
            "Image Name: 139_2_20240305_m.tif\n",
            "Class: late-recruits\n",
            "Bounding Box: [170.62803649902344, 44.33633041381836, 1558.710693359375, 1483.5740966796875]\n",
            "Pixels: 1442088\n",
            "Pixel Size X: 5.3544117109764935\n",
            "Pixel Size Y: 5.354411710976494\n",
            "Area: 41344266.0550459 µm^2\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: ''",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/content/sam2/Coral_Area_Generator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0mimage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%run Coral_Area_Generator.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}